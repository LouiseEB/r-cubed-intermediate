# Analyzing your tidy data {#dplyr-2}

![](https://img.shields.io/badge/document%20status-in%20progress-red?style=flat-square)

```{r, eval=TRUE, child="resources/preamble.Rmd"}
```

`r '<!-- '`

```{r}
knitr::opts_chunk$set(eval = FALSE)
```

Here we will cover the fourth block, "*Work with final data*" in Figure \@ref(fig:diagram-overview-4)

```{r diagram-overview-4, fig.cap="Section of the overall workflow we will be covering.", echo=FALSE}
diagram_overview(4)
```

Day 2 afternoon (13:15, end at 16:45 --- ~3.5 hrs, with one big break, one small one during exercise):

    - more on functions
        - debugging (print, stop)
        - using with tidyverse
    - saving data and summarizing final
        - load_all
        - across, where, tidyselect helpers
        
- deeper into dplyr
    - tidyselect helpers
    - across and where
    - regular expressions?
    - joins
    - Possible uses:
        - calculating mean
            - summarize across is numeric (select where is.numeric)
            - show off the ... here (like with na.rm)
            - Like for the RR or actigraph
        - Any time you think you would use a for loop, use this.
        
- debugging in functions
    - breaks in RStudio?
    - basics like print.
    
- creating functions
    - and when using tidyverse functions

    - Possible uses:
        - calculating mean from df
            - select only numeric (select where is.numeric)
            - show off the ... here (like with na.rm)
        - Run multiple models and extract only some information
        - Run models on re-sampled sets
        - Combining with parallel processing?
            - Don't get them to do this, just show it.
    - Show but don't get them to do: other versions of functions in purrr
    
    - Include some final dplyr summarizing of results of mmash
    
- slides afterward
    - Incorporate open and reproducible practices in coding

Post course?

## Code:

vroom takes file as a vector, so naively you could give it all the filenames
and let it read them in.. but then you don't know where the data came from.
Two solutions:

- imap_dfr with fs filenames with .id = "ID"
- vroom with id = "ID"

Show both to give example of how vroom works under the hood with imap 

```{r}
library(vroom)
library(here)
library(dplyr)
user_1_rr_file <- here("data-raw/mmash/user_1/RR.csv")
user_1_rr_data <- vroom(
    user_1_rr_file,
    col_select = -1,
    col_types = cols(
        ibi_s = col_double(),
        day = col_double(),
        # Converts to seconds
        time = col_time(format = "")
    )
) %>% 
    rename(inter_beat_interval_seconds = ibi_s)

user_1_rr_data %>% 
    group_by(day) %>% 
    summarize(across(inter_beat_interval_seconds, 
                     list(mean = mean, min = min, max = max)))

user_1_rr_data %>% 
    group_by(day) %>% 
    # functional programming
    summarize(across(inter_beat_interval_seconds, 
                     list(mean = mean, min = min, max = max, sd = sd)))

```


## Misc



```{r add-function-arguments, error=TRUE}
mean_sd_by_group <- function(.dataset, .groupvar) {
    by_group_output <- .dataset %>% 
        select(.groupvar, BMI, TotChol, Pulse, BPSysAve, BPDiaAve) %>% 
        gather(Measurement, Value, -.groupvar) %>% 
        na.omit() %>% 
        group_by(.groupvar, Measurement) %>% 
        summarise(Mean = round(mean(Value), 2),
                  SD = round(sd(Value), 2),
                  MeanSD = str_c(Mean, " (", SD, ")")) %>% 
        select(-Mean, -SD) %>% 
        spread(.groupvar, MeanSD)
    return(by_group_output)
}
mean_sd_by_group(NHANES, Gender)
```

What happened? We had an error. We've encountered a problem due to
"[non-standard evaluation]" (or NSE). NSE is very commonly used in most tidyverse
packages as well as throughout base R. It's one of the first things computer 
scientists complain about when they use R, because it is such a foreign thing
in other programming languages. But NSE is what allows you to use formulas (e.g.
`y ~ x + x2` in modelling) or allows you to type out `select(Gender, BMI)`. In
other programming languages, it would be `select("Gender", "BMI")`. It gives a lot
of flexibility to use for doing data analysis, but can give some headaches when
programming in R. So instead we have to use quotes instead and use the `_at()` 
combined with `vars()` version of dplyr functions. The tidyr functions `gather`
and `spread` don't require these changes.

[non-standard evaluation]: https://adv-r.had.co.nz/Computing-on-the-language.html

```{r add-function-arguments-error, error=TRUE}
mean_sd_by_group <- function(.dataset, .groupvar) {
    by_group_output <- .dataset %>% 
        select_at(vars(.groupvar, BMI, TotChol, Pulse, BPSysAve, BPDiaAve)) %>% 
        gather(Measurement, Value, -.groupvar) %>% 
        na.omit() %>% 
        group_by_at(vars(.groupvar, Measurement)) %>% 
        summarise(Mean = round(mean(Value), 2),
                  SD = round(sd(Value), 2),
                  MeanSD = str_c(Mean, " (", SD, ")")) %>% 
        select(-Mean, -SD) %>% 
        spread(.groupvar, MeanSD)
    return(by_group_output)
}
mean_sd_by_group(NHANES, "Gender")
```

Now we can also use other categorical variables:

```{r use-other-category-vars}
mean_sd_by_group(NHANES, "SurveyYr")
mean_sd_by_group(NHANES, "Diabetes")
```


### Easier to use parallel processing with map

One big reason to get comfortable and good at using map is because you can use
parallel processing to speed up your analysis with the `future_` series of
functions from the [furrr] package.

[furrr]: https://davisvaughan.github.io/furrr/index.html

```{r parallel-processing, eval=FALSE}
library(furrr)
# Use a combination of more of your CPU or creating multiple R sessions
plan(multiprocess)
```


`r '-->'`
