# Continued hands-on exercises {#hands-on-work}

:::: {.alert .alert-warning .hints-alert}
::: {.hints-container}
Note: We're still testing to see what best works for this section.
:::
::::

For the most part, we thought the best way to reinforce and practice the
skills learned in this course is to apply them to your own datasets or projects.
So we set aside time in the schedule for this work under the heading of "project work".

## Exercise: Import and process the activity data

Time: 25 minutes

**This is an optional exercise if there is extra time (or to do during the group work session)**.
We have a few other datasets that we could join together, but would likely require
more processing in order to appropriately join with the other datasets.
Complete these tasks in the `doc/lesson.Rmd` file:

1. Create a new header called `## Exercise: Importing activity data`
1. Create a new code chunk below this new header.
1. Starting the workflow from the beginning (e.g. with the `spec()` process),
write code that imports the `Activity.csv` data into R. 
1. Convert this code into a new function using the workflow you've used from
this course:
    - Call the new function `import_activity`.
    - Include one argument called `file_path`
    - Test that it works.
    - Add Roxygen documentation and explicit package links (`::`) with the
    functions.
    - Move the newly created function into the `R/functions.R`.
    - Use the new function in `doc/lesson.Rmd` and use `source()`
    (`Ctrl-Shift-S`) to run it.
1. Import all the `user_` datasets with `import_multiple_files()` and the
`import_activity()` function.
1. Pipe the results into `mutate()` and create a new column called
`activity_seconds` that is based on subtracting `end` and `start`.
    - Use `?mutate` and check the examples in the help document that pops up if you don't recall how to use this
    function.
1. **Add and commit** your changes to the Git history.

Look into the [Data Description][mmash-site] and find out what each column
represents and what the numbers mean in the column `activity`. Then brainstorm
with your group:

1. The disadvantage of using numbers instead of text to describe categorical
data like in the `activity` column.
1. Ways you could include this information into the dataset.
1. How you could meaningfully join this dataset with the other datasets.

[mmash-site]: https://physionet.org/content/mmash/1.0.0/

```{r solution-import-activity, results='hide', solution=TRUE, eval=FALSE}
import_activity <- function(file_path) {
    activity_data <- vroom::vroom(
        file_path,
        col_select = -1,
        col_types = vroom::cols(
            activity = vroom::col_double(),
            start = vroom::col_time(format = ""),
            end = vroom::col_time(format = ""),
            day = vroom::col_double(),
            .delim = ","
        ),
        .name_repair = snakecase::to_snake_case
    ) 
    return(activity_data)
}

activity_df <- import_multiple_files("Activity.csv", import_activity)

activity_df %>% 
    mutate(activity_duration = end - start)
```

## Exercise: Process and join sleep and questionnaire data

Time: 30 min

**This is an *optional* exercise and could also be done during the group work time.**

There are still a few datasets that you can join in with the current
datasets like `sleep.csv` and `questionnaire.csv`. 
Using the workflows in Section \@ref(general-workflow) as a guide,
start from the beginning and import, process, clean, make functions,
and join these two datasets in with the others so that they get 
included in the `data/mmash.rda` final dataset. Afterwards, do some
descriptive analysis using the function `tidy_summarise_by_day()`.

**Note**: User 11 has no sleep data, so you will eventually have to drop
user 11 from the dataset before summarizing the data.

## Exercise: Create a second dataset of only the Actigraph and RR data

Time: 30 min

**This is an *optional* exercise and could also be done during the group work time.**

The Actigraph and RR datasets contain a lot of interesting and useful
data that gets destroyed when we first summarise and then join them
with the other datasets. While we can't meaningfully join all this
data with the other datasets, we can join them on their own as separate datasets.

Using the workflows in Section \@ref(general-workflow) as a guide,
start from the beginning and import, process, clean, make functions,
and create a final dataset of only the `Actigraph.csv` and `RR.csv`
datasets.

- Join only these two datasets by `user_id`, `day`, and `time`.
- Name the new dataset `actigraph_rr` and save it to `data/`
by using another `usethis::use_data()` line in the `data-raw/mmash.R`
script.


However, if you don't have data to work on, you have several other options:

- Work more on the MMASH dataset, analyzing it and exploring it more.
- Practice the skills and tools learned by starting from beginning on a new
dataset. For this option, there are several data sources you could use like
[PhysioNet](https://physionet.org/about/database/#open) or 
[Zenodo](https://zenodo.org/search?page=1&size=20&q=diabetes&access_right=open&file_type=xlsx&file_type=csv&file_type=zip&type=dataset#).
Here are two possible datasets you could use that require the skills and tools 
we covered in this course:
    - [Data on the 2021 Olympics in Tokyo](https://www.kaggle.com/arjunprasadsarkhel/2021-olympics-in-tokyo)
    - [RR interval time series from healthy subjects](https://physionet.org/content/rr-interval-healthy-subjects/1.0.0/) 
- Work on the game ["Murder Mystery"](https://andersaskeland.github.io/R-murder-mystery) (which Anders converted into a game using R).
